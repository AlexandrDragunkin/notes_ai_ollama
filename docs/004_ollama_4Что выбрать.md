
**Рекомендации по выбору модели для разных режимов работы**

| Режим | Описание задач | Рекомендуемая модель | Обоснование |
|-------|----------------|----------------------|-------------|
| **Debug** | Поиск ошибок, анализ стека вызовов, объяснение поведения кода, генерация исправлений | **qwen3-coder:480b-cloud** | Специализирована на анализе и исправлении кода, хорошо понимает контекст ошибок, предлагает точные исправления. |
| **Architect** | Проектирование архитектуры, выбор паттернов, декомпозиция модулей, документирование структуры | **deepseek-v3.1:671b-cloud** | Очень большая модель, способна к глубокому анализу и проектированию сложных систем, хорошо работает с абстракциями. |
| **Orchestrator** | Планирование многошаговых задач, координация между модулями, управление зависимостями | **kimi-k2:1t-cloud** | Наибольшая модель в списке → лучшее понимание долгосрочных задач, способна удерживать контекст на протяжении всей сессии. |

### Альтернативные варианты

| Режим | Альтернатива | Когда использовать |
|-------|--------------|--------------------|
| Debug | **gpt-oss:120b-cloud** | Если qwen3-coder недоступна, но нужна точность выше, чем у 20B. |
| Architect | **qwen3-coder:480b-cloud** | Если важна не только логика, но и конкретные примеры кода/паттернов. |
| Orchestrator | **deepseek-v3.1:671b-cloud** | Если kimi-k2 слишком медленная, но нужна хорошая координация задач. |

### Как переключать модели в разных режимах

Если ваша IDE или плагин поддерживает указание модели в настройках, вы можете задать разные значения для каждого режима:

#### Пример настройки в Roo Code (или аналогичном плагине)

1. Откройте **Settings** (`Ctrl+,`).  
2. Найдите параметры **Roo Code: API Endpoint** и **Roo Code: Model Name**.  
3. Для каждого режима укажите соответствующую модель:

| Режим | Model Name |
|-------|------------|
| Debug | `qwen3-coder:480b-cloud` |
| Architect | `deepseek-v3.1:671b-cloud` |
| Orchestrator | `kimi-k2:1t-cloud` |

Если плагин не поддерживает разные модели для разных режимов, можно использовать **одну универсальную модель** – **`deepseek-v3.1:671b-cloud`**. Она даёт хороший баланс между точностью, пониманием контекста и возможностью решать задачи из всех трёх категорий.

### Краткое резюме

- **Debug** → `qwen3-coder:480b-cloud` (лучшее понимание ошибок и исправлений).  
- **Architect** → `deepseek-v3.1:671b-cloud` (глубокий анализ и проектирование).  
- **Orchestrator** → `kimi-k2:1t-cloud` (удержание контекста и координация).  
- **Универсальный выбор** → `deepseek-v3.1:671b-cloud` (если нужна одна модель на все задачи).  

Если вы используете облачный API, убедитесь, что у вас есть доступ к выбранным моделям и учтены лимиты по токенам/запросам.